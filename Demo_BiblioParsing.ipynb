{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346cb308-2424-4970-87ca-b51484213781",
   "metadata": {},
   "source": [
    "# BiblioParsing demonstration tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef6123-1e5c-4c76-8ba6-a4f2d53917b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the working folder  \n",
    "# as set in the json file \"~\\BiblioParsing\\DemoConfig\\BiblioParsing_config.json\"\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Getting the working folder name \n",
    "config_tup = bp.set_user_config()\n",
    "working_folder_path = config_tup[0]\n",
    "\n",
    "print(f\"Working folder path: {working_folder_path}\") \n",
    "\n",
    "print(\"\\nCell run completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2978a-1c90-40bb-844e-4dc5b6a402cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of building the architecture of the working folder in the user's path home,\n",
    "# for a corpus year \"year\" using `build_files_paths` function of the `DemoUtils` module,\n",
    "# and getting useful paths for demo as described in the json file:\n",
    "#   \"~\\BiblioParsing\\DemoConfig\\BiblioParsing_config.json\".\n",
    "# This function takes into account the list of databases which raw data should be parsed.\n",
    "# The user is invited to put the raw data in the dedicated folder.\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Setting the corpus year\n",
    "year = <\"####\">\n",
    "print(\"Parsing year:\",year,\"\\n\")\n",
    "\n",
    "# Setting the list of databases to parse\n",
    "db_list = [bp.SCOPUS, bp.WOS]\n",
    "\n",
    "# Building the working folder architecture for a corpus single year \"year\" and getting useful paths\n",
    "config_tup = bp.set_user_config(year, db_list)\n",
    "rawdata_path_dict, parsing_path_dict = config_tup[1], config_tup[2]\n",
    "\n",
    "scopus_raw_path     = rawdata_path_dict[bp.SCOPUS]\n",
    "scopus_parsing_path = parsing_path_dict[bp.SCOPUS]\n",
    "print(f\"\\nPut the 'csv' file extracted from the Scopus database in:\\n   {scopus_raw_path}\")\n",
    "print(f\"\\nThe parsing results for the Scopus rawdata will be saved in:\\n   {scopus_parsing_path}\")\n",
    "\n",
    "wos_raw_path     = rawdata_path_dict[bp.WOS]\n",
    "wos_parsing_path = parsing_path_dict[bp.WOS]\n",
    "print(f\"\\nPut the 'txt' file extracted from the WoS database in:\\n   {wos_raw_path}\")\n",
    "print(f\"\\nThe parsing results for the WoS rawdata will be saved in:\\n   {wos_parsing_path}\")\n",
    "\n",
    "concat_parsing_path = parsing_path_dict['concat']\n",
    "print(f\"\\nThe concatenated parsing results will be saved in:\\n   {concat_parsing_path}\")\n",
    "\n",
    "dedup_parsing_path = parsing_path_dict['dedup']\n",
    "print(f\"\\nThe deduplicated parsing results will be saved in:\\n   {dedup_parsing_path}\")   \n",
    "    \n",
    "print(\"\\nCell run completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5773eee-701e-4ac0-9006-0faa9d681798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parsing Scopus raw data\n",
    "# using `biblio_parser_scopus` function of `BiblioParsingScopus` module.\n",
    "# Then saving results as xlsx files using `save_parsing_dict` \n",
    "# and `save_fails_dict` functions of `DemoUtils`module.\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Setting the corpus year\n",
    "year = <\"####\">\n",
    "print(\"Parsing year:\",year,\"\\n\")\n",
    "\n",
    "# Setting the user's xlsx files for mormalizing institutions \n",
    "# if set to None, use of default files of BiblioParsing_RefFiles folder\n",
    "user_institute_affiliations_file_path = Path(<your_fullpath_to_institute_affiliations_file>)\n",
    "user_inst_types_file_path = Path(<your_fullpath_to_inst_types_file>)\n",
    "user_country_towns_folder_path = Path(<your_fullpath_to_country_towns_folder>)\n",
    "user_country_towns_file = Path(<your_country_towns_file_name>)\n",
    "\n",
    "# Setting the list of databases to parse\n",
    "db_list = [bp.SCOPUS, bp.WOS]\n",
    "\n",
    "# Building the working folder architecture for a corpus single year \"year\" and getting useful paths\n",
    "config_tup = bp.set_user_config(year, db_list)\n",
    "rawdata_path_dict, parsing_path_dict, item_filename_dict = config_tup[1], config_tup[2], config_tup[3]\n",
    "\n",
    "# Setting the files type for saving results\n",
    "save_extent = \"xlsx\"\n",
    "\n",
    "# Parsing Scopus rawdata\n",
    "print(\"Scopus parsing launched...\")\n",
    "scopus_raw_path = rawdata_path_dict[bp.SCOPUS]\n",
    "scopus_parsing_dict, scopus_fails_dict = bp.biblio_parser_scopus(scopus_raw_path,\n",
    "                                                                 inst_filter_list = None,\n",
    "                                                                 country_affiliations_file_path = user_institute_affiliations_file_path,\n",
    "                                                                 inst_types_file_path = user_inst_types_file_path,\n",
    "                                                                 country_towns_file = user_country_towns_file,\n",
    "                                                                 country_towns_folder_path = user_country_towns_folder_path)\n",
    "if scopus_parsing_dict:\n",
    "\n",
    "    # Saving parsing results as xlsx files\n",
    "    print(\"Results saving launched...\")\n",
    "    scopus_parsing_path = parsing_path_dict[bp.SCOPUS]\n",
    "    message = bp.save_parsing_dict(scopus_parsing_dict, scopus_parsing_path, \n",
    "                                   item_filename_dict, save_extent)\n",
    "    print(\"\\n\",message)\n",
    "\n",
    "    # Saving parsing fails as json file\n",
    "    message = bp.save_fails_dict(scopus_fails_dict, scopus_parsing_path)\n",
    "    print(\"\\n\",message)\n",
    "    print(\"\\nCell run completed\")\n",
    "\n",
    "else:\n",
    "    print(bp.set_rawdata_error(bp.SCOPUS, scopus_raw_path, bp.SCOPUS_RAWDATA_EXTENT))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d87ee-63ab-4e61-95bb-afd0e6c72f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parsing WoS rawdata \n",
    "# using `biblio_parser_wos` function of `BiblioParsingWos` module.\n",
    "# Then saving results as xlsx files using `save_parsing_dict` \n",
    "# and `save_fails_dict` functions of `DemoUtils`module.\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Setting the corpus year\n",
    "year = <\"####\">\n",
    "print(\"Parsing year:\",year,\"\\n\")\n",
    "\n",
    "# Setting the user's xlsx files for mormalizing institutions \n",
    "# if set to None, use of default files of BiblioParsing_RefFiles folder\n",
    "user_institute_affiliations_file_path = Path(<your_fullpath_to_institute_affiliations_file>)\n",
    "user_inst_types_file_path = Path(<your_fullpath_to_inst_types_file>)\n",
    "user_country_towns_folder_path = Path(<your_fullpath_to_country_towns_folder>)\n",
    "user_country_towns_file = Path(<your_country_towns_file_name>)\n",
    "\n",
    "# Setting the list of databases to parse\n",
    "db_list = [bp.SCOPUS, bp.WOS]\n",
    "\n",
    "# Building the working folder architecture for a corpus single year \"year\" and getting useful paths\n",
    "config_tup = bp.set_user_config(year, db_list)\n",
    "rawdata_path_dict, parsing_path_dict, item_filename_dict = config_tup[1], config_tup[2], config_tup[3]\n",
    "\n",
    "# Setting the files type for saving results\n",
    "save_extent = \"xlsx\"\n",
    "\n",
    "# Parsing WoS rawdata\n",
    "print(\"WoS parsing launched...\")\n",
    "wos_raw_path = rawdata_path_dict[bp.WOS]\n",
    "wos_parsing_dict, wos_fails_dict = bp.biblio_parser_wos(wos_raw_path,\n",
    "                                                        inst_filter_list = None,\n",
    "                                                        country_affiliations_file_path = user_institute_affiliations_file_path,\n",
    "                                                        inst_types_file_path = user_inst_types_file_path,\n",
    "                                                        country_towns_file = user_country_towns_file,\n",
    "                                                        country_towns_folder_path = user_country_towns_folder_path)\n",
    "if wos_parsing_dict:\n",
    "    \n",
    "    # Saving parsing results as xlsx files\n",
    "    print(\"Results saving launched...\")\n",
    "    wos_parsing_path = parsing_path_dict[bp.WOS]\n",
    "    message = bp.save_parsing_dict(wos_parsing_dict, wos_parsing_path, \n",
    "                                   item_filename_dict, save_extent)\n",
    "    print(\"\\n\",message)\n",
    "\n",
    "    # Saving parsing fails as json file \n",
    "    message = bp.save_fails_dict(wos_fails_dict, wos_parsing_path)\n",
    "    print(\"\\n\",message)\n",
    "    print(\"\\nCell run completed\")\n",
    "    \n",
    "else:\n",
    "    print(bp.set_rawdata_error(bp.WOS, wos_raw_path, bp.WOS_RAWDATA_EXTENT))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939cad6-3721-4d23-b99a-696d47350f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of concatenating and deduplicating Scopus and WoS parsings\n",
    "# using `concatenate_parsing` and `deduplicate_parsing` functions of `BiblioParsingConcat` module.\n",
    "# Then saving results as xlsx files using `save_parsing_dict` function of `DemoUtils` module.\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Setting the corpus year\n",
    "year = <\"####\">\n",
    "print(\"Parsing year:\",year,\"\\n\")\n",
    "\n",
    "# Setting the user's authors affiliations filter as a list of tuples (institution normalized name, institution column name)\n",
    "user_inst_filter_list = [(<normalized name 1>, <column name 1>),\n",
    "                         (<normalized name 2>, <column name 2>),\n",
    "                         ...]\n",
    "print(\"User's institutions filter list:\", user_inst_filter_list,\"\\n\")\n",
    "\n",
    "# Setting the user's xlsx files for mormalizing institutions \n",
    "# if set to None, use of default files of BiblioParsing_RefFiles folder\n",
    "user_institute_affiliations_file_path = Path(<your_fullpath_to_institute_affiliations_file>)\n",
    "user_country_affiliations_file_path = Path(<your_fullpath_to_country_affiliations_file>)\n",
    "user_inst_types_file_path = Path(<your_fullpath_to_inst_types_file>)\n",
    "user_country_towns_folder_path = Path(<your_fullpath_to_country_towns_folder>)\n",
    "user_country_towns_file = Path(<your_country_towns_file_name>)\n",
    "\n",
    "# Setting the user's status of building normalized institutions file and raw institutions file after deduplicating parsing\n",
    "user_norm_inst_status = True\n",
    "\n",
    "# Setting the list of databases to parse\n",
    "db_list = [bp.SCOPUS, bp.WOS]\n",
    "\n",
    "# Building the working folder architecture for a corpus single year \"year\" and getting useful paths\n",
    "config_tup = bp.set_user_config(year, db_list)\n",
    "rawdata_path_dict, parsing_path_dict, item_filename_dict = config_tup[1], config_tup[2], config_tup[3]\n",
    "\n",
    "# Setting the files type for saving results\n",
    "save_extent = \"xlsx\"\n",
    "\n",
    "# Parsing Scopus rawdata\n",
    "print(\"Scopus parsing launched...\")\n",
    "scopus_raw_path = rawdata_path_dict[bp.SCOPUS]\n",
    "scopus_parsing_dict, _ = bp.biblio_parser_scopus(scopus_raw_path,\n",
    "                                                 inst_filter_list = None,\n",
    "                                                 country_affiliations_file_path = user_institute_affiliations_file_path,\n",
    "                                                 inst_types_file_path = user_inst_types_file_path,\n",
    "                                                 country_towns_file = user_country_towns_file,\n",
    "                                                 country_towns_folder_path = user_country_towns_folder_path)\n",
    "\n",
    "# Parsing WoS rawdata\n",
    "print(\"WoS parsing launched...\")\n",
    "wos_raw_path = rawdata_path_dict[bp.WOS]\n",
    "wos_parsing_dict, _ = bp.biblio_parser_wos(wos_raw_path,\n",
    "                                           inst_filter_list = None,\n",
    "                                           country_affiliations_file_path = user_institute_affiliations_file_path,\n",
    "                                           inst_types_file_path = user_inst_types_file_path,\n",
    "                                           country_towns_file = user_country_towns_file,\n",
    "                                           country_towns_folder_path = user_country_towns_folder_path)  \n",
    "\n",
    "if scopus_parsing_dict and wos_parsing_dict:\n",
    "\n",
    "    # Parsings concatenation\n",
    "    print(\"Concatenation of Scopus and WoS parsings launched...\")\n",
    "    concat_parsing_path = parsing_path_dict['concat']\n",
    "    concat_parsing_dict = bp.concatenate_parsing(scopus_parsing_dict, wos_parsing_dict,  \n",
    "                                                 inst_filter_list = user_inst_filter_list)\n",
    "    _ = bp.save_parsing_dict(concat_parsing_dict, concat_parsing_path, item_filename_dict, save_extent)\n",
    "\n",
    "    # Parsings deduplication\n",
    "    print(\"Deduplication of Scopus and WoS parsings launched...\")\n",
    "    dedup_parsing_path = parsing_path_dict['dedup']\n",
    "    dedup_parsing_dict = bp.deduplicate_parsing(concat_parsing_dict, \n",
    "                                                norm_inst_status = user_norm_inst_status,\n",
    "                                                inst_types_file_path = user_inst_types_file_path,\n",
    "                                                country_affiliations_file_path = user_country_affiliations_file_path,\n",
    "                                                country_towns_file = user_country_towns_file,\n",
    "                                                country_towns_folder_path = user_country_towns_folder_path)\n",
    "    message = bp.save_parsing_dict(dedup_parsing_dict, dedup_parsing_path, item_filename_dict, save_extent)\n",
    "    print(\"\\n\",message)\n",
    "    print(\"\\nCell run completed\")\n",
    "\n",
    "else:\n",
    "    if not scopus_parsing_dict:\n",
    "        print(bp.set_rawdata_error(bp.SCOPUS, scopus_raw_path, bp.SCOPUS_RAWDATA_EXTENT))\n",
    "    if not wos_parsing_dict:\n",
    "        print(bp.set_rawdata_error(bp.WOS, wos_raw_path, bp.WOS_RAWDATA_EXTENT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad237-e8ba-4b0f-97e9-36876fa1ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parsing Scopus and WoS rawdata, then concatenating un deduplicating parsings results\n",
    "# using `parse_to_dedup` function of `DemoUtils` module.\n",
    "# Then saving results as tsv files with \".dat\" extension and xlsx files\n",
    "# using `save_parsing_dicts` function of `DemoUtils` module.\n",
    "\n",
    "# Local library imports\n",
    "import BiblioParsing as bp\n",
    "\n",
    "# Setting the corpus year\n",
    "year = <\"####\">\n",
    "print(\"Parsing year:\",year,\"\\n\")\n",
    "\n",
    "# Setting the user's authors affiliations filter as a list of tuples (institution normalized name, institution column name)\n",
    "user_inst_filter_list = [(<normalized name 1>, <column name 1>),\n",
    "                         (<normalized name 2>, <column name 2>),\n",
    "                         ...]\n",
    "print(\"User's institutions filter list:\", user_inst_filter_list,\"\\n\")\n",
    "\n",
    "# Setting the user's xlsx files for mormalizing institutions \n",
    "# if set to None, use of default files of BiblioParsing_RefFiles folder\n",
    "user_institute_affiliations_file_path = Path(<your_fullpath_to_institute_affiliations_file>)\n",
    "user_country_affiliations_file_path = Path(<your_fullpath_to_country_affiliations_file>)\n",
    "user_inst_types_file_path = Path(<your_fullpath_to_inst_types_file>)\n",
    "user_country_towns_folder_path = Path(<your_fullpath_to_country_towns_folder>)\n",
    "user_country_towns_file = Path(<your_country_towns_file_name>)\n",
    "\n",
    "# Setting the user's status for building dicts of normalized institutions \n",
    "# and of not-yet normalized institutions for further normalization\n",
    "user_norm_inst_status = True\n",
    "\n",
    "# Setting the list of databases to parse\n",
    "db_list = [bp.SCOPUS, bp.WOS]\n",
    "\n",
    "# Building the working folder architecture for a corpus single year \"year\" and getting useful paths\n",
    "config_tup = bp.set_user_config(year, db_list)\n",
    "rawdata_path_dict, parsing_path_dict, item_filename_dict = config_tup[1], config_tup[2], config_tup[3]\n",
    "\n",
    "# Setting the rawdata path for Scopus and WoS \n",
    "db_raw_dict = {}\n",
    "db_raw_dict[bp.SCOPUS] = rawdata_path_dict[bp.SCOPUS]\n",
    "db_raw_dict[bp.WOS]    = rawdata_path_dict[bp.WOS]\n",
    "\n",
    "# Parsing rawdata of Scopus and WoS database, then concatenate and deduplicate the results\n",
    "print(\"Parsing to deduplication of Scopus and WoS data launched...\")\n",
    "parsing_dicts_dict, fails_dicts = bp.parse_to_dedup(year, db_raw_dict, \n",
    "                                                    user_inst_filter_list,\n",
    "                                                    user_norm_inst_status,\n",
    "                                                    user_istitute_affiliations_file_path,\n",
    "                                                    user_inst_types_file_path,\n",
    "                                                    user_country_affiliations_file_path,\n",
    "                                                    user_country_towns_file,\n",
    "                                                    user_country_towns_folder_path,\n",
    "                                                    verbose = False)   \n",
    "if parsing_dicts_dict:\n",
    "    \n",
    "    # Saving results as tsv files with \".dat\" extension\n",
    "    tsv_save_extent = \"dat\"\n",
    "    message = bp.save_parsing_dicts(parsing_dicts_dict, parsing_path_dict, \n",
    "                                    item_filename_dict, tsv_save_extent, fails_dicts)\n",
    "    print(\"\\n\", message)\n",
    "\n",
    "    # Saving results as xslx files\n",
    "    xlsx_save_extent = \"xlsx\"\n",
    "    message = bp.save_parsing_dicts(parsing_dicts_dict, parsing_path_dict, \n",
    "                                    item_filename_dict, xlsx_save_extent, fails_dicts)\n",
    "    print(\"\\n\", message)\n",
    "    print(\"\\nCell run completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26300cf4-88a9-48b1-9876-d0a4fb681bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioParsing_ker",
   "language": "python",
   "name": "biblioparsing_ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
